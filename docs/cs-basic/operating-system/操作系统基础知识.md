> 本文来自JavaGuide，郎涯进行简单排版与补充



**为什么要学习操作系统**

操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。

比如说我们开发的系统使用的缓存（比如 Redis）和操作系统的高速缓存就很像。CPU 中的高速缓存有很多种，不过大部分都是为了解决 CPU 处理速度和内存处理速度不对等的问题。我们还可以把内存看作外存的高速缓存，程序运行的时候我们把外存的数据复制到内存，由于内存的处理速度远远高于外存，这样提高了处理速度。同样地，我们使用的 Redis 缓存就是为了解决程序处理速度和访问常规关系型数据库速度不对等的问题。

高速缓存一般会按照局部性原理（2-8 原则）根据相应的淘汰算法保证缓存中的数据是经常会被访问的。我们平常使用的 Redis 缓存很多时候也会按照 2-8 原则去做，很多淘汰算法都和操作系统中的类似。既说了 2-8 原则，那就不得不提命中率了，这是所有缓存概念都通用的。简单来说也就是你要访问的数据有多少能直接在缓存中直接找到。命中率高的话，一般表明你的缓存设计比较合理，系统处理速度也相对较快。

关于如何学习操作系统，可以看这篇回答：[https://www.zhihu.com/question/270998611/answer/1640198217](https://www.zhihu.com/question/270998611/answer/1640198217)。



## 操作系统基础

### 什么是操作系统

- 操作系统（Operating System，简称 OS）是**管理计算机硬件与软件资源的程序**，是计算机的基石

- 操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件

- 操作系统存在**屏蔽了硬件层的复杂性**。操作系统就像是硬件使用的负责人，统筹着各种相关事项

- 操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理。 **内核是连接应用程序和硬件的桥梁**，决定着系统的性能和稳定性

![Kernel_Layout](https://img-note.langyastudio.com/202111122112574.png?x-oss-process=style/watermark)

### 系统调用

**用户态和系统态**

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

- 用户态(user mode) 

  用户态运行的进程可以直接读取用户程序的数据

- 系统态(kernel mode)

  系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制



**系统调用**

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！也就是说在我们运行的用户程序中，凡是**与系统态级别的资源有关的操作**（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：

- 设备管理

  完成设备的请求或释放，以及设备启动等功能

- 文件管理

  完成文件的读、写、创建及删除等功能

- 进程控制

  完成进程的创建、撤销、阻塞及唤醒等功能

- 进程通信

  完成进程之间的消息传递或信号传递等功能

- 内存管理

  完成内存的分配、回收以及获取作业占用内存区大小及地址等功能



## 进程和线程

### 进程 vs 线程

下图是 Java 内存区域，我们从 JVM 的角度来说一下线程和进程之间的关系吧！

![](https://img-note.langyastudio.com/202112021046807.png?x-oss-process=style/watermark)

从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的**程序计数器**、**虚拟机栈** 和 **本地方法栈**。

**总结：** 线程是进程划分成的更小的运行单位,一个进程在其执行的过程中可以产生多个线程。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。



### 进程有哪几种状态

- 创建状态(new)

  进程正在被创建，尚未到就绪状态

- 就绪状态(ready)

  进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行

- 运行状态(running)

  进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)

- 阻塞状态(waiting)

  又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行

- 结束状态(terminated)

  进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行

> 订正：下图中 running 状态被 interrupt 向 ready 状态转换的箭头方向反了。

![process-state](https://img-note.langyastudio.com/202111122111653.png?x-oss-process=style/watermark)



### 进程间的通信方式

> 下面这部分总结参考了:[《进程间通信 IPC (InterProcess Communication)》](https://www.jianshu.com/p/c1015f5ffa74) 这篇文章，推荐阅读，总结的非常不错。

- 管道/匿名管道(**Pipes**)

  用于具有亲缘关系的父子进程间或者兄弟进程之间的通信

- 有名管道(**Names Pipes**)

  匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循**先进先出(first in first out)**。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信

- 信号(**Signal**)

  信号是一种比较复杂的通信方式，用于**通知接收进程某个事件**已经发生

- 消息队列(**Message Queuing**)

  消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少**，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

- 信号量(**Semaphores**)

  信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于**进程间同步**。这种通信方式主要用于解决与同步相关的问题并避免竞争条件

- 共享内存(**Shared memory**)

  使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式

- 套接字(**Sockets**)

  此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程



### 线程间的同步方式

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

- **互斥量**(Mutex)

  采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为**互斥对象只有一个**，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制

- **信号量**(Semphares)

  它**允许同一时刻多个线程访问同一资源**，但是需要控制同一时刻访问此资源的最大线程数量

- **事件**(Event)

  Wait/Notify：通过**通知**操作的方式来保持多线程同步，还可以方便地实现多线程优先级的比较



### 进程的调度算法

为了确定首先执行哪个进程以及最后执行哪个进程以实现最大 CPU 利用率，计算机科学家已经定义了一些算法，它们是：

- **先到先服务**(FCFS)调度算法

  从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度

- **短作业优先**(SJF)的调度算法

  从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度

- **时间片轮转**调度算法

  时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间

- **优先级调度**算法

  为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级

- **多级反馈队列**调度算法

  前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程 。多级反馈队列调度算法**既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。**因而它是目前被公认的一种较好的进程调度算法，**UNIX 操作系统采取的便是这种调度算法**

  

### 什么是死锁

多个进程可以竞争有限数量的资源。当一个进程申请资源时，如果这时没有可用资源，那么这个进程进入等待状态。有时，如果所申请的资源被其他等待进程占有，那么该等待进程有可能再也无法改变状态。这种情况称为**死锁**。



### 死锁的四个条件

如果系统中以下四个条件同时成立，那么就能引起死锁：

- 互斥

  资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止

- 占有并等待

  一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有

- 非抢占

  资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放

- 循环等待

  有一组等待进程 `{P0, P1,..., Pn}`，  `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，......，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有



## 内存管理基础

### 内存管理介绍

操作系统的内存管理主要负责**内存的分配与回收**（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。



### 常见的内存管理机制

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如块式管理。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如页式管理和段式管理。

- **块式管理** 

  远古时代的计算机操系统的内存管理方式。将**内存分为几个固定大小的块，每个块中只包含一个进程**。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片

  

- **页式管理** 

  把主存分为大小相等且固定的一页一页的形式，**页较小**，相对相比于块式管理的划分力度更大，**提高了内存利用率**，减少了碎片。页式管理通过**页表**对应逻辑地址和物理地址

- **段式管理** 

  页式管理虽然提高了内存利用率，但是页式管理其中的**页实际并无任何实际意义**。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是最重要的是段是有实际意义的，**每个段定义了一组逻辑信息**，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过**段表**对应逻辑地址和物理地址

- **段页式管理机制** 

  段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说段页式管理机制中段与段之间以及段的内部的都是离散的



### 快表和多级页表

在分页内存管理中，很重要的两点是：

- 虚拟地址到物理地址的转换要快

- 解决虚拟地址空间大，页表也会很大的问题



#### 快表

**为了解决虚拟地址到物理地址的转换速度**，操作系统在**页表方案**基础之上引入了**快表**来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（**Cache**），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表
2. 如果该页在快表中，直接从快表中读取相应的物理地址
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页

看完了之后你会发现快表和我们平时经常在我们开发的系统使用的缓存（比如 Redis）很像，的确是这样的，操作系统中的很多思想、很多经典的算法，你都可以在我们日常开发使用的各种工具或者框架中找到它们的影子。



#### 多级页表

引入多级页表的主要目的是为了**避免把全部页表一直放在内存中占用过多空间**，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章

- 多级页表如何节约内存：[https://www.polarxiong.com/archives/多级页表如何节约内存.html](https://www.polarxiong.com/archives/多级页表如何节约内存.html)



#### 总结

为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 不论是快表还是多级页表实际上都利用到了程序的局部性原理，局部性原理在后面的虚拟内存这部分会介绍到。



### 分页机制 vs 分段机制

**共同点** ：

- 分页机制和分段机制都是为了**提高内存利用率**，减少内存碎片

- 页和段都是**离散存储**的，所以两者都是离散分配内存的方式。但是每个页和段中的内存是连续的

  

**区别** ：

- **页的大小是固定的，由操作系统决定**；而段的大小不固定，取决于我们当前运行的程序
- 分页仅仅是为了满足操作系统内存管理的需求，而**段是逻辑信息的单位**，在程序中可以体现为代码段，数据段，能够更好满足用户的需要



### 逻辑(虚拟)地址 vs 物理地址

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，**逻辑地址由操作系统决定**。**物理地址指的是真实物理内存中地址**，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。



### CPU 寻址

> 这部分内容参考了 Microsoft 官网的介绍，地址：<https://docs.microsoft.com/zh-cn/windows-hardware/drivers/gettingstarted/virtual-address-spaces?redirectedfrom=MSDN>

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。使用虚拟寻址，**CPU 需要将虚拟地址翻译成物理地址**，这样才能访问到真实的物理内存。 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。如下图所示：

![MMU_principle_updated](https://img-note.langyastudio.com/202111301715571.png?x-oss-process=style/watermark)



**为什么要有虚拟地址空间呢**

先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

- 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）**破坏操作系统**，造成操作系统崩溃

- 想要同时**运行多个程序特别困难**，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃

总结：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。



通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列**相邻的虚拟地址**来访问物理内存中不相邻的大内存缓冲区
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动
- 不同进程使用的虚拟地址**彼此隔离**。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存



## 虚拟内存

### 什么是虚拟内存

这个在我们平时使用电脑特别是 Windows 系统的时候太常见了。很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存。为什么可以这样呢？ 正是因为虚拟内存的存在，通过虚拟内存可以**让程序可以拥有超过系统物理内存大小的可用内存空间**。另外虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）。这样会更加有效地管理内存并减少出错。

虚拟内存是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。虚拟内存的重要意义是**定义了一个连续的虚拟地址空间，并且把内存扩展到硬盘空间**。推荐阅读：[《虚拟内存的那点事儿》](https://juejin.im/post/59f8691b51882534af254317)

> 虚拟存储器又叫做虚拟内存，都是 Virtual Memory 的翻译，属于同一个概念
>
> 这部分内容来自：[王道考研操作系统知识点整理](https://wizardforcel.gitbooks.io/wangdaokaoyan-os/content/13.html)



### 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以**只装入部分程序到内存就开始运行**。

> 以下内容摘自《计算机操作系统教程》 第 4 章存储器管理

早在 1968 年的时候，就有人指出我们的程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。

局部性原理表现在以下两个方面：

- **时间局部性** 

  如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作

- **空间局部性** 

  一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。**虚拟内存技术实际上就是建立了 “内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。**

虚拟内存同样是一种时间换空间的策略，你用 CPU 的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。不得不感叹，程序世界几乎不是时间换空间就是空间换时间。



### 虚拟内存的技术实现

虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式：

- **请求分页存储** 

  建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分页即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。

- **请求分段存储** 

  建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。

- **请求段页式存储**



**请求分页 vs 分页存储**

请求分页存储管理建立在分页管理之上。他们的根本区别是**是否将程序全部所需的全部地址空间都装入主存**，请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。

不管是上面那种实现方式，我们一般都需要：

- 一定容量的内存和外存

  在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了

- **缺页中断**

  如果需执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段调入到内存，然后继续执行程序

- **虚拟地址空间** 

  逻辑地址到物理地址的变换



### 页面置换算法

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断

> **缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则

- OPT 页面置换算法（**最佳页面置换算法** ）

  最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法

- FIFO（First In First Out） 页面置换算法（**先进先出页面置换算法** ）

  总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰

- LRU （Least Recently Used）页面置换算法（**最近最久未使用页面置换算法** ）

  LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰

- LFU （Least Frequently Used）页面置换算法（**最少使用页面置换算法** ）

  该置换算法选择在之前时期使用最少的页面作为淘汰页



## Reference

- 《计算机操作系统—汤小丹》第四版
- [《深入理解计算机系统》](https://book.douban.com/subject/1230413/)
- [https://zh.wikipedia.org/wiki/输入输出内存管理单元](https://zh.wikipedia.org/wiki/输入输出内存管理单元)
- [https://baike.baidu.com/item/快表/19781679](https://baike.baidu.com/item/快表/19781679)
- https://www.jianshu.com/p/1d47ed0b46d5
- <https://www.studytonight.com/operating-system>
- <https://www.geeksforgeeks.org/interprocess-communication-methods/>
- <https://juejin.im/post/59f8691b51882534af254317>
- 王道考研操作系统知识点整理： https://wizardforcel.gitbooks.io/wangdaokaoyan-os/content/13.html













